---
title:  "Research about Visual Question Answering Published in ArXiv"
excerpt: "Visual Question Answering (VQA) is a recent topic in computer vision and natural language processing that has attracted a great deal of attention from deep learning, computer vision and natural language processing communities..  I have tried to collect and curate some publications form Arxiv that related to the visual question answering, and the results were listed here. Please enjoy it! "
date: 2020-08-14
permalink: /posts/2020/08/research-about-visual-question-answering-published-in-arxiv/
categories: [computer-vision,natural-language-processing]
tags: [visual-question-answering]
---

Visual Question Answering (VQA) is a recent topic in computer vision and natural language processing that has attracted a great deal of attention from deep learning, computer vision and natural language processing communities. [(Kafle and Kanan, 2017)](https://doi.org/10.1016/j.cviu.2017.06.005). I have tried to collect and curate some publications form Arxiv that related to the visual question answering, and the results were listed here. Please enjoy it! 

Last updated: **August 14, 2020** <br />
Source      : [**ArXiv**](https://arxiv.org/)

|No.| Year  |  Title | URL      |
|:-:| :---: | ------ | :------: |
|1|2020|Visual Question Answering Using Semantic Information from Image Descriptions| [View](https://arxiv.org/abs/2004.10966) |
|2|2020|Understanding Knowledge Gaps in Visual Question Answering: Implications for Gap Identification and Testing| [View](https://arxiv.org/abs/2004.03755) |
|3|2020|Generating Rationales in Visual Question Answering| [View](https://arxiv.org/abs/2004.02032) |
|4|2020|PathVQA: 30000+ Questions for Medical Visual Question Answering| [View](https://arxiv.org/abs/2003.10286) |
|5|2020|RUBi: Reducing Unimodal Biases in Visual Question Answering| [View](https://arxiv.org/abs/1906.10169) |
|6|2020|VQA-LOL: Visual Question Answering under the Lens of Logic| [View](https://arxiv.org/abs/2002.08325) |
|7|2020|Component Analysis for Visual Question Answering Architectures| [View](https://arxiv.org/abs/2002.05104) |
|8|2020|Augmenting Visual Question Answering with Semantic Frame Information in a Multitask Learning Approach| [View](https://arxiv.org/abs/2001.11673) |
|9|2020|Robust Explanations for Visual Question Answering| [View](https://arxiv.org/abs/2001.08730) |
|10|2020|Generating Question Relevant Captions to Aid Visual Question Answering| [View](https://arxiv.org/abs/1906.00513) |
|11|2019|Assessing the Robustness of Visual Question Answering| [View](https://arxiv.org/abs/1912.01452) |
|12|2019|Self-Critical Reasoning for Robust Visual Question Answering| [View](https://arxiv.org/abs/1905.09998) |
|13|2019|Learning Sparse Mixture of Experts for Visual Question Answering| [View](https://arxiv.org/abs/1909.09192) |
|14|2019|Inverse Visual Question Answering with Multi-Level Attentions| [View](https://arxiv.org/abs/1909.07583) |
|15|2019|Decoupled Box Proposal and Featurization with Ultrafine-Grained Semantic Labels Improve Image Captioning and Visual Question Answering| [View](https://arxiv.org/abs/1909.02097) |
|16|2019|VideoNavQA: Bridging the Gap between Visual and Embodied Question Answering| [View](https://arxiv.org/abs/1908.04950) |
|17|2019|Fusion of Detected Objects in Text for Visual Question Answering| [View](https://arxiv.org/abs/1908.05054) |
|18|2019|An Empirical Study on Leveraging Scene Graphs for Visual Question Answering| [View](https://arxiv.org/abs/1907.12133) |
|19|2019|A Comparative Evaluation of Visual and Natural Language Question Answering Over Linked Data| [View](https://arxiv.org/abs/1907.08501) |
|20|2019|Quantifying and Alleviating the Language Prior Problem in Visual Question Answering| [View](https://arxiv.org/abs/1905.04877) |
|21|2019|GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering| [View](https://arxiv.org/abs/1902.09506) |
|22|2019|Generating Natural Language Explanations for Visual Question Answering using Scene Graphs and Visual Attention| [View](https://arxiv.org/abs/1902.05715) |
|23|2018|Textually Enriched Neural Module Networks for Visual Question Answering| [View](https://arxiv.org/abs/1809.08697) |
|24|2018|Faithful Multimodal Explanation for Visual Question Answering| [View](https://arxiv.org/abs/1809.02805) |
|25|2018|Question-Guided Hybrid Convolution for Visual Question Answering| [View](https://arxiv.org/abs/1808.02632) |
|26|2018|Interpretable Visual Question Answering by Visual Grounding from Attention Supervision Mining| [View](https://arxiv.org/abs/1808.00265) |
|27|2018|Learning Visual Question Answering by Bootstrapping Hard Attention| [View](https://arxiv.org/abs/1808.00300) |
|28|2018|Question Relevance in Visual Question Answering| [View](https://arxiv.org/abs/1807.08435) |
|29|2018|Learning Visual Knowledge Memory Networks for Visual Question Answering| [View](https://arxiv.org/abs/1806.04860) |
|30|2018|Think Visually: Question Answering through Virtual Imagery| [View](https://arxiv.org/abs/1805.11025) |
|31|2018|R-VQA: Learning Visual Relation Facts with Semantic Attention for Visual Question Answering| [View](https://arxiv.org/abs/1805.09701) |
|32|2018|Reciprocal Attention Fusion for Visual Question Answering| [View](https://arxiv.org/abs/1805.04247) |
|33|2018|Explicit Reasoning over End-to-End Neural Architectures for Visual Question Answering| [View](https://arxiv.org/abs/1803.08896) |
|34|2018|Attention on Attention: Architectures for Visual Question Answering (VQA)| [View](https://arxiv.org/abs/1803.07724) |
|35|2018|Co-attending Free-form Regions and Detections with Multi-modal Multiplicative Feature Embedding for Visual Question Answering| [View](https://arxiv.org/abs/1711.06794) |
|36|2018|Learning to Count Objects in Natural Images for Visual Question Answering| [View](https://arxiv.org/abs/1802.05766) |
|37|2018|Dual Recurrent Attention Units for Visual Question Answering| [View](https://arxiv.org/abs/1802.00209) |
|38|2017|Interpretable Counting for Visual Question Answering| [View](https://arxiv.org/abs/1712.08697) |
|39|2017|Don't Just Assume; Look and Answer: Overcoming Priors for Visual Question Answering| [View](https://arxiv.org/abs/1712.00377) |
|40|2017|Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge| [View](https://arxiv.org/abs/1708.02711) |
|41|2017|MemexQA: Visual Memex Question Answering| [View](https://arxiv.org/abs/1708.01336) |
|42|2017|Visual Question Answering with Memory-Augmented Networks| [View](https://arxiv.org/abs/1707.04968) |
|43|2017|Learning Convolutional Text Representations for Visual Question Answering| [View](https://arxiv.org/abs/1705.06824) |
|44|2017|Survey of Visual Question Answering: Datasets and Techniques| [View](https://arxiv.org/abs/1705.03865) |
|45|2017|Speech-Based Visual Question Answering| [View](https://arxiv.org/abs/1705.00464) |
|46|2017|The Promise of Premise: Harnessing Question Premises in Visual Question Answering| [View](https://arxiv.org/abs/1705.00601) |
|47|2017|C-VQA: A Compositional Split of the Visual Question Answering (VQA) v1| [View](https://arxiv.org/abs/1704.08243) |
|48|2017|Being Negative but Constructively: Lessons Learnt from Creating Better Visual Question Answering Datasets| [View](https://arxiv.org/abs/1704.07121) |
|49|2017|An Analysis of Visual Question Answering Algorithms| [View](https://arxiv.org/abs/1703.09684) |
|50|2017|Recurrent and Contextual Models for Visual Question Answering| [View](https://arxiv.org/abs/1703.08120) |
|51|2017|VQABQ: Visual Question Answering by Basic Questions| [View](https://arxiv.org/abs/1703.06492) |
|52|2017|Task-driven Visual Saliency and Attention-based Visual Question Answering| [View](https://arxiv.org/abs/1702.06700) |
|53|2016|VIBIKNet: Visual Bidirectional Kernelized Network for Visual Question Answering| [View](https://arxiv.org/abs/1612.03628) |
|54|2016|Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering| [View](https://arxiv.org/abs/1612.00837) |
|55|2016|Zero-Shot Visual Question Answering| [View](https://arxiv.org/abs/1611.05546) |
|56|2016|Hierarchical Question-Image Co-Attention for Visual Question Answering| [View](https://arxiv.org/abs/1606.00061) |
|57|2016|Proposing Plausible Answers for Open-ended Visual Question Answering| [View](https://arxiv.org/abs/1610.06620) |
|58|2016|Visual Question Answering: Datasets, Algorithms, and Future Challenges| [View](https://arxiv.org/abs/1610.01465) |
|59|2016|The Color of the Cat is Gray: 1 Million Full-Sentences Visual Question Answering (FSVQA)| [View](https://arxiv.org/abs/1609.06657) |
|60|2016|Graph-Structured Representations for Visual Question Answering| [View](https://arxiv.org/abs/1609.05600) |
|61|2016|Measuring Machine Intelligence Through Visual Question Answering| [View](https://arxiv.org/abs/1608.08716) |
|62|2016|Interpreting Visual Question Answering Models| [View](https://arxiv.org/abs/1608.08974) |
|63|2016|Analyzing the Behavior of Visual Question Answering Models| [View](https://arxiv.org/abs/1606.07356) |
|64|2016|Human Attention in Visual Question Answering: Do Humans and Deep Networks Look at the Same Regions?| [View](https://arxiv.org/abs/1606.03556) |
|65|2016|Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding| [View](https://arxiv.org/abs/1606.01847) |
|66|2016|Hierarchical Co-Attention for Visual Question Answering| [View](https://arxiv.org/abs/1606.00061) |
|67|2016|Ask Your Neurons: A Deep Learning Approach to Visual Question Answering| [View](https://arxiv.org/abs/1605.02697) |
|68|2016|A Focused Dynamic Attention Model for Visual Question Answering| [View](https://arxiv.org/abs/1604.01485) |
|69|2016|Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering| [View](https://arxiv.org/abs/1511.05234) |
|70|2016|VQA: Visual Question Answering| [View](https://arxiv.org/abs/1505.00468) |
|71|2016|Dynamic Memory Networks for Visual and Textual Question Answering| [View](https://arxiv.org/abs/1603.01417) |
