---
title:  "Curated Lists of Publications about Abstractive Summarization from ArXiv"
excerpt: "Abstractive summary is a technique in which the summary is created by either rephrasing or using the new words, rather than simply extracting the relevant phrases."
date: 2020-05-16
permalink: /posts/2020/05/curated-lists-of-publications-about-abstractive-summarization-from-arxiv/
---

Abstractive summary is a technique in which the summary is created by either rephrasing or using the new words, rather than simply extracting the relevant phrases (Gupta et. al., 2019). I have tried to collect and curate some publications form Arxiv that related to the abstractive summarization, and the results were listed here. Please enjoy it! 

Last updated: **May 16, 2020** <br />
Source      : [**ArXiv**](https://arxiv.org/)

|No.| Year  |  Title | URL      |
|:-:| :---: | ------ | :------: |
|1|2020|On Faithfulness and Factuality in Abstractive Summarization| [View](https://arxiv.org/abs/2005.00661) |
|2|2020|Attend to Medical Ontologies: Content Selection for Clinical Abstractive Summarization| [View](https://arxiv.org/abs/2005.00163) |
|3|2020|Neural Abstractive Summarization with Structural Attention| [View](https://arxiv.org/abs/2004.09739) |
|4|2020|Aspect and Opinion Aware Abstractive Review Summarization with Reinforced Hard Typed Decoder| [View](https://arxiv.org/abs/2004.05755) |
|5|2020|End-to-End Abstractive Summarization for Meetings| [View](https://arxiv.org/abs/2004.02016) |
|6|2020|Amharic Abstractive Text Summarization| [View](https://arxiv.org/abs/2003.13721) |
|7|2020|Abstractive Text Summarization based on Language Model Conditioning and Locality Modeling| [View](https://arxiv.org/abs/2003.13027) |
|8|2020|Abstractive Summarization with Combination of Pre-trained Sequence-to-Sequence and Saliency Models| [View](https://arxiv.org/abs/2003.13028) |
|9|2020|Boosting Factual Correctness of Abstractive Summarization with Knowledge Graph| [View](https://arxiv.org/abs/2003.08612) |
|10|2020|Learning by Semantic Similarity Makes Abstractive Summarization Better| [View](https://arxiv.org/abs/2002.07767) |
|11|2020|Abstractive Summarization for Low Resource Data using Domain Transfer and Data Synthesis| [View](https://arxiv.org/abs/2002.03407) |
|12|2020|Length-controllable Abstractive Summarization by Guiding with Summary Prototype| [View](https://arxiv.org/abs/2001.07331) |
|13|2020|Neural Abstractive Text Summarization with Sequence-to-Sequence Models: A Survey| [View](https://arxiv.org/abs/1812.02303) |
|14|2020|Deep Reinforced Self-Attention Masks for Abstractive Summarization ( )| [View](https://arxiv.org/abs/2001.00009) |
|15|2020|In Conclusion Not Repetition: Comprehensive Abstractive Summarization With Diversified Attention Based On Determinantal Point Processes| [View](https://arxiv.org/abs/1909.10852) |
|16|2019|Improving Abstractive Text Summarization with History Aggregation| [View](https://arxiv.org/abs/1912.11046) |
|17|2019|PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization| [View](https://arxiv.org/abs/1912.08777) |
|18|2019|SAMSum Corpus: A Human-annotated Dialogue Dataset for Abstractive Summarization| [View](https://arxiv.org/abs/1911.12237) |
|19|2019|Contrastive Attention Mechanism for Abstractive Sentence Summarization| [View](https://arxiv.org/abs/1910.13114) |
|20|2019|Attention Optimization for Abstractive Document Summarization| [View](https://arxiv.org/abs/1910.11491) |
|21|2019|Concept Pointer Network for Abstractive Summarization| [View](https://arxiv.org/abs/1910.08486) |
|22|2019|Abstractive Dialog Summarization with Semantic Scaffolds| [View](https://arxiv.org/abs/1910.00825) |
|23|2019|SummAE: Zero-Shot Abstractive Text Summarization using Length-Agnostic Auto-Encoders| [View](https://arxiv.org/abs/1910.00998) |
|24|2019|Analyzing Sentence Fusion in Abstractive Summarization| [View](https://arxiv.org/abs/1910.00203) |
|25|2019|Summary Level Training of Sentence Rewriting for Abstractive Summarization| [View](https://arxiv.org/abs/1909.08752) |
|26|2019|How to Write Summaries with Patterns? Learning towards Abstractive Summarization through Prototype Editing| [View](https://arxiv.org/abs/1909.08837) |
|27|2019|An Entity-Driven Framework for Abstractive Summarization| [View](https://arxiv.org/abs/1909.02059) |
|28|2019|Deep Reinforcement Learning with Distributional Semantic Rewards for Abstractive Summarization| [View](https://arxiv.org/abs/1909.00141) |
|29|2019|Abstractive Document Summarization without Parallel Data| [View](https://arxiv.org/abs/1907.12951) |
|30|2019|Ontology-Aware Clinical Abstractive Summarization| [View](https://arxiv.org/abs/1905.05818) |
|31|2019|Neural Abstractive Text Summarization and Fake News Detection| [View](https://arxiv.org/abs/1904.00788) |
|32|2019|Abstractive Summarization of Spoken and Written Conversation| [View](https://arxiv.org/abs/1902.01615) |
|33|2019|MeanSum: A Model for Unsupervised Neural Multi-document Abstractive Summarization| [View](https://arxiv.org/abs/1810.05739) |
|34|2018|Abstractive Text Summarization by Incorporating Reader Comments| [View](https://arxiv.org/abs/1812.05407) |
|35|2018|Neural Abstractive Text Summarization with Sequence-to-Sequence Models| [View](https://arxiv.org/abs/1812.02303) |
|36|2018|Abstractive Summarization of Reddit Posts with Multi-level Memory Networks| [View](https://arxiv.org/abs/1811.00783) |
|37|2018|Abstractive Summarization Using Attentive Neural Techniques| [View](https://arxiv.org/abs/1810.08838) |
|38|2018|Unsupervised Neural Multi-document Abstractive Summarization| [View](https://arxiv.org/abs/1810.05739) |
|39|2018|Robust Neural Abstractive Summarization Systems and Evaluation against Adversarial Information| [View](https://arxiv.org/abs/1810.06065) |
|40|2018|The Rule of Three: Abstractive Text Summarization in Three Bullet Points| [View](https://arxiv.org/abs/1809.10867) |
|41|2018|Bidirectional Attentional Encoder-Decoder Model and Bidirectional Beam Search for Abstractive Summarization| [View](https://arxiv.org/abs/1809.06662) |
|42|2018|Abstractive Dialogue Summarization with Sentence-Gated Modeling Optimized by Dialogue Acts| [View](https://arxiv.org/abs/1809.05715) |
|43|2018|Unsupervised Abstractive Sentence Summarization using Length Controlled Variational Autoencoder| [View](https://arxiv.org/abs/1809.05233) |
|44|2018|Bottom-Up Abstractive Summarization| [View](https://arxiv.org/abs/1808.10792) |
|45|2018|Guided Neural Language Generation for Abstractive Summarization using Abstract Meaning Representation| [View](https://arxiv.org/abs/1808.09160) |
|46|2018|Entity Commonsense Representation for Neural Abstractive Summarization| [View](https://arxiv.org/abs/1806.05504) |
|47|2018|Structure-Infused Copy Mechanisms for Abstractive Summarization| [View](https://arxiv.org/abs/1806.05658) |
|48|2018|Toward Abstractive Summarization Using Semantic Representations| [View](https://arxiv.org/abs/1805.10399) |
|49|2018|Fast Abstractive Summarization with Reinforce-Selected Sentence Rewriting| [View](https://arxiv.org/abs/1805.11080) |
|50|2018|Global Encoding for Abstractive Summarization| [View](https://arxiv.org/abs/1805.03989) |
|51|2018|Regularizing Output Distribution of Abstractive Chinese Social Media Text Summarization for Improved Semantic Consistency| [View](https://arxiv.org/abs/1805.04033) |
|52|2018|A Reinforced Topic-Aware Convolutional Sequence-to-Sequence Model for Abstractive Text Summarization| [View](https://arxiv.org/abs/1805.03616) |
|53|2018|Towards a Neural Network Approach to Abstractive Multi-Document Summarization| [View](https://arxiv.org/abs/1804.09010) |
|54|2018|A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents| [View](https://arxiv.org/abs/1804.05685) |
|55|2018|Abstractive Tabular Dataset Summarization via Knowledge BaseSemantic Embeddings| [View](https://arxiv.org/abs/1804.01503) |
|56|2018|Actor-Critic based Training Framework for Abstractive Summarization| [View](https://arxiv.org/abs/1803.11070) |
|57|2018|Deep Communicating Agents for Abstractive Summarization| [View](https://arxiv.org/abs/1803.10357) |
|58|2018|A Hybrid Word-Character Model for Abstractive Summarization| [View](https://arxiv.org/abs/1802.09968) |
|59|2018|Diverse Beam Search for Increased Novelty in Abstractive Summarization| [View](https://arxiv.org/abs/1802.01457) |
|60|2018|Query Focused Abstractive Summarization: Incorporating Query Relevance, Multi-Document Coverage, and Summary Length Constraints into seq2seq Models| [View](https://arxiv.org/abs/1801.07704) |
|61|2017|Query-Based Abstractive Summarization Using Neural Networks| [View](https://arxiv.org/abs/1712.06100) |
|62|2017|Generative Adversarial Network for Abstractive Text Summarization| [View](https://arxiv.org/abs/1711.09357) |
|63|2017|Faithful to the Original: Fact Aware Neural Abstractive Summarization| [View](https://arxiv.org/abs/1711.04434) |
|64|2017|Order-Preserving Abstractive Summarization for Spoken Content Based on Connectionist Temporal Classification| [View](https://arxiv.org/abs/://ift.tt/) |
|65|2017|Deep Recurrent Generative Decoder for Abstractive Text Summarization| [View](https://arxiv.org/abs/1708.00625) |
|66|2017|A Pilot Study of Domain Adaptation Effect for Neural Abstractive Summarization| [View](https://arxiv.org/abs/1707.07062) |
|67|2017|A Deep Reinforced Model for Abstractive Summarization| [View](https://arxiv.org/abs/1705.04304) |
|68|2017|Diversity driven Attention Model for Query-based Abstractive Summarization| [View](https://arxiv.org/abs/1704.08300) |
|69|2017|Selective Encoding for Abstractive Sentence Summarization| [View](https://arxiv.org/abs/1704.07073) |
|70|2017|Cutting-off Redundant Repeating Generations for Neural Abstractive Summarization| [View](https://arxiv.org/abs/1701.00138) |
|71|2016|Abstractive Meeting Summarization UsingDependency Graph Fusion| [View](https://arxiv.org/abs/1609.07035) |
|72|2016|The Role of CNL and AMR in Scalable Abstractive Summarization for Multilingual Media Monitoring| [View](https://arxiv.org/abs/1606.05994) |
|73|2016|Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond| [View](https://arxiv.org/abs/1602.06023) |
